---
title: "線形モデル: OLS と Stackingへの応用"
subtitle: "経済学のための機械学習入門"
author: "川田恵介"
format: 
  revealjs:
    html-math-method: katex
    css: styles.css
    slide-number: true
self-contained: true
self-contained-math: true
bibliography: ref.bib
execute: 
  warning: false
  message: false
  eval: true
  echo: false
---

# Model aggregation

```{r}
pacman::p_load(
  tidyverse,
  arrow,
  mlr3verse,
  simpr,
  DiagrammeR
)

lgr::get_logger("mlr3")$set_threshold("error")
lgr::get_logger("bbotk")$set_threshold("error")

Data <- read_parquet(
  "Public/Example.parquet"
)

Noise <- 50
FigLower <- -20
FigUpper <- 60

N <- 100

SimData <- function(i,n){
  set.seed(i)
  TempData <- tibble(
    X = runif(n,-4,4),
    TrueY = 0.5*(X^2) + 
      if_else(X <= -2,
              10,
              0) + 
      if_else(X <= 0,
              10,
              0) + 
      if_else(X <= 2,
              10,
              0),
    Y = TrueY + runif(n,-Noise,Noise)
  )
  return(TempData)
}

TestData <- SimData(100,10000)

EstDeepTree <- function(i,n){
  TempData <- SimData(i,n)
  TempPred <- rpart::rpart(
    Y ~ X,
    TempData,
    control = rpart::rpart.control(
      cp = 0,
      maxdepth = 30,
      minsplit = 50,
      minbucket = 50
    )
  ) |> 
    predict(TestData)
  TempResult <- TestData |> 
    mutate(
    Pred = TempPred,
    ID = i |> factor()
  )
  return(TempResult)
}

TempResult <- EstDeepTree(1,1000) |> 
  bind_rows(
    EstDeepTree(2,1000)
  ) |> 
  bind_rows(
    EstDeepTree(3,1000)
  ) |> 
  bind_rows(
    EstDeepTree(4,1000)
  ) |> 
  mutate(
    Aggregate = mean(Pred),
    .by = "X")
```

## 比喩: 予測屋会議

- 複数の"専門家"の予測を集計して最終予測モデルとする

    - "エコノミスト"の見通しの平均値
    
    - 専門家委員会

- 一人の予測に頼るよりもいいのではないか

    - 教室付き学習にも応用可能な発送

## 数値例

- 独立してサンプリングしたデータについて、深い予測木 (剪定なし) を推定

- 各予測値と、予測値の平均を比較

## Estimation Error

```{r, dev='ragg_png'}
TempResult |> 
  ggplot(
    aes(
      x = X,
      y = Pred,
      color = ID
    )
  ) +
  theme_bw() +
  geom_point() +
  geom_smooth(
    aes(
      y = TrueY
    ),
    method = "lm",
    formula = y ~ 0 + I(x^2) + I(if_else(x <= -2,1,0))
    + I(if_else(x <= 0,1,0))
    + I(if_else(x <= 2,1,0)),
    color = "black"
  ) +
  facet_wrap(
    ~ ID
  ) +
  ylim(FigLower,FigUpper)
```

## Aggregation

```{r, dev='ragg_png'}
TempResult |> 
  ggplot(
    aes(
      x = X,
      y = Pred,
      color = ID
    )
  ) +
  theme_bw() +
  geom_point(
    size = 0.5
    ) +
  geom_point(
    aes(
      y = Aggregate,
      color = "平均"
    )
  ) +
  geom_smooth(
    aes(
      y = TrueY
    ),
    method = "lm",
    formula = y ~ 0 + I(x^2) + I(if_else(x <= -2,1,0))
    + I(if_else(x <= 0,1,0))
    + I(if_else(x <= 2,1,0)),
    color = "black"
  ) +
  ylim(FigLower,FigUpper)
```

## チャレンジ

- 「独立して抽出された」有限個データから生成された予測モデル

- 「独立して抽出した複数のデータから得た」予測モデルの集計は通常不可能

- 近似的に行う

    - (Nonparametric) bootstrapの活用

# Bootstrap Aggregating

- Bagging

## 決定木の不安定性

- 多くの実践で、決定木推定の不安定性(データに依存, Estimation errorが大きい)は、正則化を行っても十分に緩和できない

    - 変数や分割回数の決定など、 Discrete choiceを避けられない

- 伝統的なアプローチ (研究者がモデルを設定するOLS, サブグループ分析) では意味をなさない解決策が有効

## 理想のBagging

```{r}
grViz("digraph dot {
      graph [rankdir = UB,color = crimson]
      edge [color=black]
      node [shape = rectangle, color = darkslategray]
      A [label = 'PredictionTask']
      B [label = 'Random Sampling']
      C1 [label = 'Data1']
      C2 [label = 'Data2']
      C3 [label = 'Data3']
      D1 [label = 'Tree1']
      D2 [label = 'Tree2']
      D3 [label = 'Tree3']
      E [label = 'Aggregate']
      A -> B -> C1,C2,C3
      C1 -> D1
      C2 -> D2
      C3 -> D3
      D1,D2,D3 -> E
      }")
```


## アルゴリズム

1. Nonparametric bootstrapで、データの複製を行う (500,1000,2000程度)

2. 各複製データについて、"深い"決定木を推定

3. 各 $X$ についての予測値の平均を最終予測値とする


## 補論: Bootstrap

```{r}
grViz("digraph dot {
      graph [rankdir = UB,color = crimson]
      edge [color=black]
      node [shape = rectangle, color = darkslategray]
      A [label = 'OriginalData: ID 1;2;3']
      B1 [label = 'ID 1;1;3']
      B2 [label = 'ID 1;2;2']
      B3 [label = 'ID 2;3;3']
      C1 [label = 'Tree 1']
      C2 [label = 'Tree 2']
      C3 [label = 'Tree 3']
      A -> B1,B2,B3
      B1 -> C1
      B2 -> C2
      B3 -> C3
      }")
```

## Baggingの限界

- $g_b(X)$ 複製データ $b$ から生成されたモデルの $X$ についての予測値

    - $g_b(X)$ : 確率変数

- 非常に深い木を生成すれば、Approximation errorは減少する一方で、Estimation errorが大きくなる

    - 確率変数の平均値は一般に分散が削減できる
    
    - 独立・無相関であれば、 無限個の**複製データ**を作れば、分散を0にできる (一致性)

- Bootstrapデータは、一般に相関する

    - 古典的なサブグループ推定 (OLS)に適用しても、性能は改善しない

## RandomForest

- データ分割に用いることができる変数群をランダムに選ぶ

- 例：ある予測木の第n分割を行う際に

    - Bagging: $\{$ 年齢、性別、学歴 $\}$ から選ぶ
    
    - Random Forest: $\{$ 年齢、性別 $\}$ から選ぶ
    
        - 第 $n+1$ 分割を行う際には、 $\{$ 学歴、性別 $\}$ から選ぶ

- 目標: 予測値同士の相関を弱める

    - サンプル分割を行う際に、 $X$ かランダムに選んだ一部の変数群から変数を選ぶ
    
- 直感: 相関を強める要因は、データが多少変わっても、同じような変数を活用してしまうから

    - そこそこの予測力を持っていたとしても、強力な予測力を持つ変数の陰に隠れてしまう

## 数値例

```{r}
SimData <- function(i,n){
  set.seed(i)
  TempData <- tibble(
    X = runif(n,-4,4),
    D = if_else(X >= 0, 
                sample(0:1,n,replace = TRUE, prob = c(95/100,5/100)),
                sample(0:1,n,replace = TRUE, prob = c(5/100,95/100))
                ),
    TrueY = X + 0.5*D,
    Y = TrueY + runif(n,-Noise,Noise)
  ) |> 
    mutate(D = factor(D))
  return(TempData)
}

TestData <- SimData(100,10000)

TestData |> 
  ggplot(
    aes(
      x = X,
      y = TrueY,
      color = D
    )
  ) +
  theme_bw() +
  geom_line()
```

## 数値例

```{r}
Fit <- ranger::ranger(
  Y ~ D + X,
  SimData(1,3000),
  mtry = 2,
  max.depth = 3
  )

Pred <- predict(
  Fit,
  TestData,
  predict.all = TRUE
)

TestData |> 
  mutate(
    Pred = Pred$predictions[,1],
    ID = 1
  ) |> 
  bind_rows(
    TestData |> 
      mutate(
        Pred = Pred$predictions[,2],
        ID = 2
        )
    ) |> 
  bind_rows(
    TestData |> 
      mutate(
        Pred = Pred$predictions[,3],
        ID = 3
        )
    ) |> 
  bind_rows(
    TestData |> 
      mutate(
        Pred = Pred$predictions[,4],
        ID = 4
        )
    ) |> 
  ggplot(
    aes(
      x = X,
      y = Pred,
      color = D
    )
  ) +
  theme_bw() +
  geom_line(
    aes(
      y = TrueY,
      color = D
    )
  ) +
  geom_line() +
  facet_wrap(
    ~ ID
  )
```

## 数値例

```{r}
Fit <- ranger::ranger(
  Y ~ D + X,
  SimData(1,3000),
  mtry = 1,
  max.depth = 3
  )

Pred <- predict(
  Fit,
  TestData,
  predict.all = TRUE
)

TestData |> 
  mutate(
    Pred = Pred$predictions[,1],
    ID = 1
  ) |> 
  bind_rows(
    TestData |> 
      mutate(
        Pred = Pred$predictions[,2],
        ID = 2
        )
    ) |> 
  bind_rows(
    TestData |> 
      mutate(
        Pred = Pred$predictions[,3],
        ID = 3
        )
    ) |> 
  bind_rows(
    TestData |> 
      mutate(
        Pred = Pred$predictions[,4],
        ID = 4
        )
    ) |> 
  ggplot(
    aes(
      x = X,
      y = Pred,
      color = D
    )
  ) +
  theme_bw() +
  geom_line(
    aes(
      y = TrueY,
      color = D
    )
  ) +
  geom_line() +
  facet_wrap(
    ~ ID
  )
```

## Hyper prameter tuning

- 多くの実戦で、 パッケージが提供するdefault valuesをそのまま使っている

- Hyper parameterのチューニングについて、議論は存在し、実装されているパッケージもある

    - mlr3tuningspaces
    
    - grf

- 明確なのは、ブートストラップの回数は多ければ、多いほどよい

## 実例

```{r}
Task <- as_task_regr(
  Data,
  "Price"
)

OLS <- lrn(
  "regr.lm",
  id = "OLS")

Tree <- lrn(
  "regr.rpart"
  ) |> 
  lts()

Tree <- AutoTuner$new(
  learner = Tree,
  tuner = tnr("random_search"),
  resampling = rsmp("holdout"),
  terminator = trm(
    "evals",
    n_evals = 20)
)

Tree$id <- "OptimalTree"

RF <- lrn(
  "regr.ranger"
  ) |> 
  lts()

RF <- AutoTuner$new(
  learner = RF,
  tuner = tnr("random_search"),
  resampling = rsmp("holdout"),
  terminator = trm(
    "evals",
    n_evals = 20)
)

RF$id <- "OptimalRF"

Design <- benchmark_grid(
  tasks = Task,
  learners = list(
    OLS,
    Tree,
    lrn("regr.ranger"),
    RF
    ),
  resamplings = rsmp("holdout") 
  )

BenchMark <- benchmark(Design)

BenchMark$aggregate(msr("regr.rsq"))
```

# まとめ

## Resampling 法の整理

```{r}
grViz("digraph dot {
      graph [rankdir = UB,color = crimson]
      edge [color=black]
      node [shape = rectangle, color = darkslategray]
      A [label = 'Original Data']
      B1 [label = 'Bootstrap']
      B2 [label = 'SubSampling']
      C1 [label = 'ModelAveraging']
      D1 [label = 'Inference']
      E1 [label = 'Regulization']
      C2 [label = 'CrossFit|Validation']
      D2 [label = 'Training/Test']
      A -> B1 [label = 'With Replacement']
      A -> B2 [label = 'Without Replacement']
      B2 -> C2,D2
      B1 -> C1,D1
      C1 -> E1 [label = 'To improve prediction peformance']
      }")
```

