---
title: "Stacking/Tips"
subtitle: "機械学習の経済学への応用"
author: "川田恵介"
affiliation: "keisukekawata@iss.u-tokyo.ac.jp"
format:
  revealjs:
    incremental: true
    self-contained-math: true
execute: 
  message: false
  warning: false
  echo: false
  eval: true
bibliography: references.bib
---

# Stacking

```{r}
#| eval: true
pacman::p_load(tidyverse,
               DiagrammeR,
               patchwork,
               mlr3verse,
               mlr3pipelines,
               recipes,
               DALEX,
               DALEXtra)
```

```{r SetUp}
set.seed(111)

lgr::get_logger("mlr3")$set_threshold("error")
lgr::get_logger("bbotk")$set_threshold("error")

TestData <- tibble(X = seq(-2,2,0.01),
                   D = 1) |> 
  bind_rows(tibble(X = seq(-2,2,0.01),
                   D = 0)) |> 
  mutate(AverageY = D + 2*if_else(X >= 0.5,1,0) + X^2,
         Y = AverageY + rnorm(2*(4/0.01 + 1),0,1))

SimData <- function(i,n){
  set.seed(i)
  TempData <- tibble(X = runif(n,-2,2)) |> 
    mutate(D = sample(0:1,n,replace = TRUE) |> as.numeric(),
           AverageY = D + 2*if_else(X >= 0.5,1,0) + X^2,
           Y = AverageY + rnorm(n,0,2)
           )
  return(TempData)
}

TaskTest <- as_task_regr(TestData |> 
                           select(-AverageY) |> 
                       mutate(X = poly(X,2)),
                         target = "Y",
                         id = "Test")

TaskCollectTest <- as_task_regr(TestData |> 
                       select(-AverageY) |> 
                       mutate(X2 = X^2,
                              CutX = if_else(X >= 0.5,1,0)),
                     target = "Y",
                     id = "SimulaitonCollect")


Task <- as_task_regr(SimData(1,5000) |> 
                       select(-AverageY) |> 
                       mutate(X = poly(X,2)),
                     target = "Y",
                     id = "SimulaitonWrong")


TaskCollect <- as_task_regr(SimData(1,5000) |> 
                       select(-AverageY) |> 
                       mutate(X2 = X^2,
                              CutX = if_else(X >= 0.5,1,0)),
                     target = "Y",
                     id = "SimulaitonCollect")



Stack <- pipeline_stacking(
  base_learners = list(lrn("regr.ranger",
                           id = "Ranger")
                       ),
  lrn("regr.lm",
      id = "Aggregate"),
  folds = 2,
  use_features = FALSE
  ) |> 
  as_learner()

Stack$id <- "Stacking"

Design <- benchmark_grid(tasks = list(Task,TaskCollect),
                         learners = list(lrn("regr.lm"),
                                         lrn("regr.ranger"),
                                         Stack),
                         resamplings = rsmp("cv", folds = 2)
                         )

BenchMark <- benchmark(Design)
```

## Algorithm Selection

-   多くの有力なアルゴリズム: OLS, LASSO/Ridge/ElasticNet, (Pruned) Tree, RandomForest

    -   時間があれば、 Boosting, Bayesian Additive Regression Trees (BART)

    -   NeuralNet, DeepLearningも選択肢

-   どれを使う？

    -   CrossValidation (BenchMark Test)

-   Model Aggregation (Stacking) も有力な選択肢

## Stacking

-   複数のアルゴリズムから得られた予測結果の加重平均を最終予測モデル

    -   RandomForest: **Tree** アルゴリズムから得られた予測結果の**単純**平均

-   最終予測モデル $f(X)$

$$f(X)=\underbrace{\alpha_1}_{Weight}\times \underbrace{f_1(X)}_{個別の予測値} + .. + \alpha_L\times  f_L(X)$$

## アルゴリズム

```{r}
#| eval: true

grViz("digraph dot {
      graph [rankdir = UB,color = crimson]
      edge [color=black]
      node [shape = rectangle, color = darkslategray]
      Start [label = 'X,Y']
      Test [label = 'TestData']
      Train [label = 'TrainingData']
      EstPrediction [label = 'Prediction Model']
      EstWeight [label = 'Optimal Weight']
      FinalModel [label = 'Final Model']
      Start -> Train,Test
      Train -> EstPrediction
      Train -> EstWeight [label = 'With CrossFitting']
      EstPrediction,EstWeight -> FinalModel
      Test -> FinalModel [label = 'Test']
      {rank = same; FinalModel;Test}
      }")
```

## Optimal Weight

-   例えば以下をOLS推定を行うことで、Weightを推定

$$Y_i=\alpha_1 \times f_1^{-i}(X_i) + \alpha_2\times f_2^{-i}(X_i)+u_i$$

-   $f_{l}^{-i}$ : アルゴリズム $l$ 、事例 $i$ を**含まない**データで推定された予測値

-   交差推定が利用可能

## Theoretical Guarantee

-   @le2022 : 個々のアルゴリズムと比べて、 Stackingは**漸近的**に性能が良い

    -   モデル選択ではなく、集計を推奨

## Practical Suggession

-   実践上では、微妙な改善に改善にとどまることが多いが、致命的な誤選択を避けれる

-   因果推論への応用でも強く推奨される (例えば @vansteelandt をめぐる[Discussion](https://biblio.ugent.be/publication/8762862))

## 例

-   $Y = D + 2\times I(X >= 0.5) + X^2 + \underbrace{u}_{N(0,1)}$

-   SimulationWrong = X,D,Xの二乗項を用いる

-   SimulationCollect = X,D,Xの二乗項、$X\ge 0.5$ ダミーを入れる

-   OLSと OLSとRandomForestのStackingを比較

## BenchMark

```{r ResulBenchMark}
BenchMark$aggregate(msr("regr.rsq")) |> 
  select(task_id,learner_id,regr.rsq) |> 
  knitr::kable(digits = 3)
```

## Estimated OLS Model (5000)

```{r ResultOLS}
OLS <- lrn("regr.lm")
OLS$train(TaskCollect)
TestData |> 
  mutate(Pred = OLS$predict(TaskCollectTest)$response,
         D = factor(D)) |> 
  ggplot(aes(x = X,
             y = AverageY,
             color = D)) +
  geom_line() +
  geom_line(aes(y = Pred,
                size = "Prediction")) +
  theme_bw()
```

## Estimated Stacking Model (5000)

```{r ResultStackingModel}
Est <- Stack$clone()$train(Task)
TestData |> 
  mutate(Pred = Est$predict(TaskTest)$response,
         D = factor(D)) |> 
  ggplot(aes(x = X,
             y = AverageY,
             color = D)) +
  geom_line() +
  geom_line(aes(y = Pred,
                size = "Prediction")) +
  theme_bw()
```

## Tips

-   異なるベースモデルを採用したアルゴリズムを入れる(Tree系統と線形モデル系統)

-   OLSや単純平均なども入れる

-   @phillips : より細かいSugestion

-   Some Variant

    -   [SuperLearner](https://github.com/tlverse/sl3) [@laan2007] : OLS with non-negative coeffiients を集計に用いる

    -   mlr3pipelines : より柔軟

        -   予測値 + 元の変数も用いることが可能、 任意のアルゴリズムを集計に利用可能

# まとめ

-   母平均 $\mu(X)$ を頑張って近似: $\min E[(\mu_Y(X)-Y)^2]$

-   一般に、特に有限サンプルに対して、 "one size fits all" アルゴリズムは存在しない

-   予測モデルの"構造"を真剣に論じるべきかどうかは、慎重に検討

    -   現状、あまりおすすめしない

## PreProcess

-   人間が背景知識を用いて、手助けできる

-   線形モデルにおいては、母平均のkinkを上手く近似できない

    - 背景知識からkinkが生じるポイントが予想できる場合も

## PreProcess

-   機械学習を用いるとしても、データクリーニングは重要

-   経済データではしばしば大量のカテゴリーがある変数が存在 (例: 所在地、テキスト、出身大学+学部)

    -   ダミー変数として処理すると、ほとんど0(情報量が少ない)の大量の変数が出来上がる

    -   学習性能が悪い

-   より少ない変数で近似したい(低次元のベクトル空間に埋め込む)

    -   カテゴリー変数 [@johannemann]

    -   テキスト [@gentzkow2019]

## Cross Validation

-   サンプルサイズが巨大な場合、交差検証ではなく単純な分割 (検証データと訓練データ)が現実的

-   サンプルサイズが小さい時は？

    -   非常に細かく分割する (leave one out)

    -   「ある程度の規模で分割し評価する」を繰り返す (repeated cross validation)

    -   後者をsuggest

## 推定モデル

-   通常の母集団についての統計的推論(信頼区間推定)は、極めて困難

    -   格差や不平等、因果効果研究に用いることは極めて危険

-   推定された予測モデルの性質 ($\neq$ 母集団の性質) を可視化する手法は、多く議論されている

    -   Model Interpretation

    -   なぜそのような予測になるのか、"モデルを説明する"

    -   "Fair" Algorithmに関連して盛り上がる

## 例

-   [DALEXパッケージ](https://dalex.drwhy.ai/) を利用

-   $Y = D + 2\times I(X >= 0.5) + X^2 + \underbrace{u}_{N(0,1)}$

-   X,Dを用いる

-   Partial Dependent Plot: $E_{X{-l}}[f(X_l,X_{-l})]$

    -   モデル全体の特徴を説明する

-   Shapley values: $E_{X}[f(X)|X_1,..,X_{l}]-E_{X}[f(X)|X_1,..,X_{-l}]$

    -   個別事例に対する予測結果を説明する

## Partial Dependent Plot

```{r}
TempData <- SimData(1,5000) |> select(X,D,Y)
TempTask <- as_task_regr(TempData, "Y")
TempOLS <- lrn("regr.lm")
TempOLS$train(TempTask)

mlr_expleiner <- explain_mlr3(TempOLS, 
                         data = TestData |> select(D,X), 
                         y = TestData$Y, 
                         label = "OLS", 
                         verbose = FALSE)

plot(model_profile(mlr_expleiner, 
                   variable = "X", type = "partial"))
```

## Partial Dependent Plot

```{r}
TempStack <- Stack$clone()$train(TempTask)
mlr_expleiner <- explain_mlr3(TempStack, 
                         data = TestData |> select(D,X), 
                         y = TestData$Y, 
                         label = "Stacking", 
                         verbose = FALSE)

plot(model_profile(mlr_expleiner, 
                   variable = "X", type = "partial"))
```

## Shapley Values

```{r}
TempData <- TestData |> select(D,X)
TestSample <- TempData[1,]

plot(predict_parts(mlr_expleiner,
                   new_observation = TestSample, type = "shap"))
```

## Reference
