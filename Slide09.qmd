---
title: "AIPW推定"
subtitle: "Semiparametric推定への応用"
author: "川田恵介"
format: 
  revealjs:
    html-math-method: katex
    css: styles.css
    slide-number: true
    incremental: true
    chalkboard: true
bibliography: ref.bib
execute: 
  warning: false
  message: false
  eval: true
  echo: false
---

# AIPW

```{r}
#| label: SetUp

pacman::p_load(
  tidyverse,
  mlr3verse,
  DoubleML
)

lgr::get_logger("mlr3")$set_threshold("error")

lgr::get_logger("bbotk")$set_threshold("error")
```


-   Partialling outは、 variance weightを用いたestimandを推定

    -   しばしば解釈が困難

- $D$ がカテゴリカル (densityが推定可能)であれば、 frequency weightを使ったestimandも推定可能

    -   有力な代替案: AIPW [@robins1995]

## Get Start: AIPW

1.  $E[Y|D=d,X]=g_{Y(d)}(X),E[D|X]=g_D(X)$ を教師付き学習などを用いて推定

2.  $S_i^{AIPW}$ の母平均を推定、ただし

$$S_i^{AIPW}=g_{Y(1)}(X_i)-g_{Y(0)}(X_i)$$

$$+\frac{D_i(Y_i-g_{Y(1)}(X_i))}{g_D(X_i)}-\frac{(1-D_i)(Y_i-g_{Y(0)}(X_i))}{1-g_D(X_i)}$$

## Summary

- AIPWとPartialling out では、 Estimand が異なることに注意

$$\tau=\int \omega_P(x)\times \tau_P(x)dx$$

-   AIPW: $\omega_P(x)=f_P(x)$ (frequency weight)

-   Partialling out: $\omega_P(x)=f_P(x)\times var_P(D_i|x)$ (variance weight)

## frequency weightへの動機づけ

- しばしば決定的に異なる: 例えば、Sub group分析

- $\int E_P[Y|D=1,X]-E_P[Y|D=0,X,Z]\times\omega_P(X)dX$ を、 $Z=\{0,1\}$ ごとに比較したい

    - $Y:$ 賃金、 $D:$ 高卒/大卒、 $X:$ 東京出身 $=1$ /その他 $=0$、 $Z:$ 1984年生まれ $=1$ /1960年生まれ $=0$
    
    - 1984年と1960年で、出身地をコントロールした上での、大卒・高卒間賃金格差を比較したい

## 結果: N = 10000

```{r}
N <- 10000

TempData <- tibble(
  Z = sample(0:1,N,replace = TRUE),
  X = sample(0:1,N,replace = TRUE),
  D = if_else(X == 1 & Z == 1,
              sample(0:1,N,replace = TRUE, prob = c(0.1,0.9)),
              sample(0:1,N,replace = TRUE)
              ),
  Y = D*if_else(X == 1,5,0) + rnorm(N)
)


TaskZ1 <- double_ml_data_from_data_frame(
  TempData |> as.data.table() |> filter(Z == 1),
  x_cols = c("X"),
  d_cols = c("D"),
  y_col = "Y"
)

TaskZ0 <- double_ml_data_from_data_frame(
  TempData |> as.data.table() |> filter(Z == 0),
  x_cols = c("X"),
  d_cols = c("D"),
  y_col = "Y"
)


FitAIPWZ1 <- DoubleMLIRM$new(
  TaskZ1,
  lrn("regr.lm"),
  lrn("classif.log_reg")
)$fit()

FitAIPWZ0 <- DoubleMLIRM$new(
  TaskZ0,
  lrn("regr.lm"),
  lrn("classif.log_reg")
)$fit()

FitPLRZ1 <- DoubleMLPLR$new(
  TaskZ1,
  lrn("regr.lm"),
  lrn("regr.lm")
)$fit()

FitPLRZ0 <- DoubleMLPLR$new(
  TaskZ0,
  lrn("regr.lm"),
  lrn("regr.lm")
)$fit()

tibble(
  Est = c(FitPLRZ0$coef,FitPLRZ1$coef,FitAIPWZ0$coef,FitAIPWZ1$coef),
  SD = c(FitPLRZ0$se,FitPLRZ1$se,FitAIPWZ0$se,FitAIPWZ1$se),
  Method = c(rep("PLR",2),rep("AIPW",2)),
  Group = rep(c("Z=0","Z=1"),2)
  ) |> 
  filter(
    Method == "PLR"
  ) |> 
  ggplot(
    aes(
      y = Group,
      x = Est,
      xmin = Est - 1.96*SD,
      xmax = Est + 1.96*SD,
      label = Est |> round(1)
    )
  ) +
  theme_bw() +
  geom_pointrange() +
  ggrepel::geom_text_repel() +
  facet_grid(
    ~ Method
  )
```

- $Z=1$ (1984年生まれ)の方が学歴間賃金格差が小さい

## なぜグループ間で差が異なるのか?

- 可能性1: $X$ が同じであったとしても、$Z=1$ の方が平均差が小さい (学歴間賃金格差が減った)

- 可能性2: 差が小さい $X$ の割合が多い (賃金格差が大きい地域で人口が減った)

- 可能性3: 差が大きい $X$ について、 $D$ の分散が大きい (?)

    - Variance weightを使って集計しているため

## 可能性1

```{r}
tibble(
  `Tau(X,Z)` = c(5,5,10,10),
  Z = c(1,1,0,0),
  X = c(1,0,1,0),
  `f(X,Z)` = c(0.25,0.25,0.25,0.25),
  `E[D|X,Z]` = c(0.5,0.5,0.5,0.5)
)
```

## 可能性2

```{r}
tibble(
  `Tau(X,Z)` = c(10,5,10,5),
  Z = c(1,1,0,0),
  X = c(1,0,1,0),
  `f(X,Z)` = c(0.15,0.35,0.25,0.25),
  `E[D|X,Z]` = c(0.5,0.5,0.5,0.5)
)
```

## 可能性3

```{r}
tibble(
  `Tau(X,Z)` = c(10,5,10,5),
  Z = c(1,1,0,0),
  X = c(1,0,1,0),
  `f(X,Z)` = c(0.25,0.25,0.25,0.25),
  `E[D|X,Z]` = c(0.9,0.5,0.5,0.5)
)
```

## 整理

```{mermaid}
graph TB
  Start(ResearchQuestion) --> B(Identification)
  B(Identification) --> C(Summary)
  C(Summary) --> |Variance weight| D1(Estimation: PartillingOut)
  C(Summary) --> |Frequency weight| D2(Estimation: AIPW)    
```

## Estimation

-   frequency weightを用いた平均差推定について、いくつか(無数?)の方法が考えられる

-   (本講義における)非推奨: (Naive) Plugin, **I**nverse **P**ropensity **W**eight (IPW)

-   推定: **A**ugmented **I**nverse **P**robability **W**eighted (AIPW)

## Plugin

1.  $E[Y|D=d,X]=g_{Y(d)}(X)$ を教師付き学習などを用いて推定

2.  $S_i^{Plugin}$ の母平均を推定、ただし

$$S_i^{Plugin}=g_{Y(1)}(X_i)-g_{Y(0)}(X_i)$$

-   $g_{Y(d)}$ の推定誤差に敏感: 一般に $\sqrt{N}$ CAN estimatorにならない

## IPW

1.  $E[D|X]=g_{D}(X)$ を教師付き学習などを用いて推定

2.  $S_i^{IPW}$ の母平均を推定、ただし

$$S_i^{IPW}=\frac{D_iY_i}{g_D(X_i)}-\frac{(1-D_i)Y_i}{1-g_D(X_i)}$$

-   $g_{D}$ の推定誤差に敏感: 一般に $\sqrt{N}$ CAN estimatorにならない

## AIPW

1.  $E[Y|D=d,X]=g_{Y(d)}(X),E[D|X]=g_D(X)$ を教師付き学習などを用いて推定

2.  $S_i^{AIPW}$ の母平均を推定、ただし

$$S_i^{AIPW}=S_i^{Plugin}$$

$$+\frac{D_i(Y_i-g_{Y(1)}(X_i))}{g_D(X_i)}-\frac{(1-D_i)(Y_i-g_{Y(0)}(X_i))}{1-g_D(X_i)}$$

## AIPWの性質

-   Partialling outと本質的に同じ性質

    -   $g_{Y(d)},g_{D}$ が少なくとも $n^{-1/4}$ よりも早い速度で $E_P[Y|D,X],E_P[D|X]$ に収束するのであれば、 推定値は $\sqrt{N}$ CAN estimatorになる

    -   注意: 一致推定量であることは大前提

-   理由も同じ

    -   Oracle推定量に $\sqrt{N}$ 以上の速度で収束する

    -   推定誤差同士の掛け算になるため

# Overlap問題

-   因果推論/比較研究における重要な**Identificationの仮定**

    -   Sumamry/Estimationにおいても厳重な注意が必要

-   注意が払われていない応用研究も散見される

## Overlapの仮定: Identification

- すべての $x$ について、 $1>E_P[D|X=x]>0$

    - 満たされないと、原理的に比較できない(母集団において存在しない)グループが存在

    - Well-specifeid modelであれば、外挿によって"可能"になる (後述)

## Overlapの重要性: Estimation

- $1>E_P[D|X=x]>0$ が成り立っていたとしても、 $E_P[D|X=x]\simeq 0 または 1$ であれば識別できても、推定困難

- AIPWの推定量も、漸近的にOracle推定量と同じ挙動をする

    - Oracle推定量の性質が悪いと、実際の統計量も性質が悪くなる

## Oracle推定への影響

$$S_i^{AIPW}=g_{Y(1)}^P(X_i)-g_{Y(1)}^P(X_i)$$

$$+\underbrace{\frac{D_i(Y_i-g_{Y(1)}^P(X_i))}{g_{D}^P(X_i)}-\frac{(1-D_i)(Y_i-g_{Y(1)}^P(X_i))}{1-g_{D}^P(X_i)}}_{"不安定"}$$

- $g^P:$ 母平均

- $g_D^P$ が0に近いグループがいれば、実質的にそのグループの実現値が推定値を決める

    - $S_i^{AIPW}$ の母分散が爆発

## 数値例

```{r}
N <- 500
SimData <- function(i,n,a){
  set.seed(i)
  TempData <- tibble(
    D = 1,
    X = 1,
    Y = rnorm(1,0,10)
    ) |> 
    bind_rows(
      tibble(
        X = sample(0:1,n,replace = TRUE),
        D = if_else(X == 1,
                    sample(0:1,n,replace = TRUE,prob = c(1-a,a)),
                    sample(0:1,n,replace = TRUE)),
        Y = rnorm(n,0,10)
        )
    )
  return(TempData)
}

SimEst <- function(i,n,a){
  TempData <- SimData(i,n,a)
  AIPW <- if_else(TempData$D == 1, TempData$Y/a, -TempData$Y/(1-a))
  TempResult <- tibble(
    Score = mean(AIPW),
    ID = i,
    Method = "AIPW",
    A = a
  ) |> 
    bind_rows(
      tibble(
    Score = TempData$Y[1],
    ID = i,
    Method = "1",
    A = a
  )
    )
  return(TempResult)
}

map_dfr(1:100,function(i){SimEst(i,N,0.5)}) |> 
  bind_rows(map_dfr(1:100,function(i){SimEst(i,N,0.05)})) |> 
  bind_rows(map_dfr(1:100,function(i){SimEst(i,N,0.01)})) |> 
  ggplot(
    aes(
      x = Score,
      y = ID,
      group = ID,
      color = Method
    )
  ) +
  theme_bw() +
  geom_vline(xintercept = 0) +
  geom_point() +
  geom_line(
    color = "black"
  ) +
  facet_grid(~A)
```


## まとめ

- $E_P[D_i|X=x]$ が0ないし1になるグループがあれば、"識別できない"

- ゼロに近いグループがいれば、**推定**困難
    
    - frequeny weightを用いたsummaryは、"実装困難"

## 注意: Overlap問題の普遍性

- かつての実証研究ではしばしば、Overlap問題に大きな関心が払われなかった

    - 計算上は、推定誤差の爆発が起きない(ただし解釈困難な)方法で推定してきた
    
    - 教科書はしばしばwell specified model を前提としてきた

## 注意: Overlap問題の普遍性

- Partialling outであれば、Overlapに問題があっても、推定値の"信頼区間"は爆発しない

    - Overlapの問題を抱えているサブグループを"無視している"だけ
    
    - 直感的な解釈からの乖離拡大

- 理想的な実験データであれば、Overlap問題は生じない

- Well-specified modelがあれば、外挿によって解決できる

    - "東京とそれ以外で賃金格差が変わらない"のを知っているので、overlapの問題が生じないサブグループで推定すれば良い

# 対応

## Research questionの修正

- 原理的に比較できないサブグループ $E[D|X]=0,1$ は、分析対象から外す

    - 直接比較を行う"実証研究"としては不適切
    
    - 他のアプローチ(理論?)で頑張る

## Moving goal posts

- 識別可能かつ推定可能なEstimandに目標変更する

    - Summaryを変える

- 有名なものとして

    - Propensity score weight

    - Triming

    - Variance weight (既習)


## Variance weight

- Variance weightであれば、推定困難なサブグループへのWeightが自動的に下がる

- Overlapが微妙でも、推定値は"安定的"だが、

    - Overlapの度合いは、Estimandの解釈に決定的に重要
    
    - Varianceが少ないグループは、勝手に無視されている

    
## Propensity score weight

- $\omega_P(X)=E_P[D|X]\times f_P(X)$ ないし $=(1-E_P[D|X])\times f_P(X)$

- $D=1$ (あるいは $D=0$)の比率が大きいサブグループを重点評価

    - Varianceよりは解釈しやすい ?

- ある種のOverlap問題を解消する

## グループサイズの不均衡への対応

- しばしば 特定の $D=d$ の人数が極めて少ない場合がある

    - 金銭的制約等により、東大生の5%のみを強制的に留学させる実験

    - $E_P[D|X]\sim 0$ が発生しがち

- $E_P[D|X]$ をWeightとして使用すれば、そのようなグループは無視される

## ATET

- 因果推論の文脈で、Propensity score weightは、Average treatment effect in treated (ないし controlled) とも呼ばれる

    - 解釈も比較的容易
    
    - 識別の家庭のもとで、介入を受けたグループ ($D=1$) 内での平均効果
    
        - ないし、受けなかったグループ内での平均効果

## まとめ

- AIPWはカテゴリカルな$D$についての、"Default standard "

    - [DoubleML vignett](https://docs.doubleml.org/stable/workflow/workflow.html)

    - ただしoverlapは深刻な問題

- 他にも選択肢

    - overlap weight [@crump2006moving]
    
    - TMLE [@van2006targeted]

    - "soft intervention" [@kennedy2019nonparametric]

- 推定の容易さ VS 解釈

    - 盛んに研究されている

## Reference
